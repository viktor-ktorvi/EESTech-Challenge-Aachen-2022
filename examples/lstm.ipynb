{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import dstack\n",
    "from pandas import read_csv\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.utils import to_categorical\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stats import extract_from_folder, extract_features\n",
    "\n",
    "def load_data():\n",
    "    folder = 'data'\n",
    "    subfolder = 'quasi-static'\n",
    "    extension = '.npz'\n",
    "    max_files = 100\n",
    "    chunk_size = 1000\n",
    "    n_pca = 4\n",
    "\n",
    "    features_quasi = extract_from_folder(folder, subfolder, extension, max_files, shuffle=False, chunk_size=chunk_size,\n",
    "                                             n_pca=n_pca).to_numpy()\n",
    "    labels_quasi = np.zeros(features_quasi.shape[1])\n",
    "\n",
    "    subfolder = 'moving'\n",
    "\n",
    "    features_moving = extract_from_folder(folder, subfolder, extension, max_files, shuffle=False, chunk_size=chunk_size,\n",
    "                                              n_pca=n_pca).to_numpy()\n",
    "\n",
    "    labels_moving = np.ones(features_moving.shape[1])\n",
    "    print(np.hstack((features_quasi, features_moving)))\n",
    "    X = np.hstack((features_quasi, features_moving)).T\n",
    "    Y = np.hstack((labels_quasi, labels_moving))\n",
    "\n",
    "    train_data, test_data, train_labels, test_labels = train_test_split(X, Y, test_size=0.2, random_state=1)\n",
    "\n",
    "    train_data = np.reshape(train_data, (1,train_data.shape[0], train_data.shape[1]))\n",
    "    test_data = np.reshape(test_data, (1,test_data.shape[0], test_data.shape[1]))\n",
    "    train_labels = np.reshape(train_labels, (1,train_labels.shape[0], 1))\n",
    "    test_labels = np.reshape(test_labels, (1,test_labels.shape[0], 1))\n",
    "    \n",
    "    return train_data, train_labels, test_data, test_labels\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,)\n",
      "(1, 10, 1)\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "data = array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n",
    "print(data.shape)\n",
    "data = data.reshape((1, 10, 1))\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1440, 4)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train\n",
    "data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = train_data.shape[2]\n",
    "n_timesteps = chunk_size/1000\n",
    "batch_size = 70\n",
    "verbose = 0\n",
    "def evaluate_model(train_data, train_labels, test_data, test_labels):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(100, input_shape=(n_timesteps,n_features))) #LSTM('no. of lstm blocks', input_shape(time_Steps,features))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(n_outputs, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # fit network\n",
    "    model.fit(train_data, train_labels, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    # evaluate model\n",
    "    _, accuracy = model.evaluate(test_data, test_labels, batch_size=batch_size, verbose=0)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 900)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# f_quasi_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = f_quasi_np\n",
    "# validation = np.array(validation)\n",
    "# test = np.array(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_dataset(prefix=''):\n",
    "# \t# load all train\n",
    "# \ttrainX, trainy = load_dataset_group('train', prefix + 'HARDataset/')\n",
    "# \tprint(trainX.shape, trainy.shape)\n",
    "# \t# load all test\n",
    "# \ttestX, testy = load_dataset_group('test', prefix + 'HARDataset/')\n",
    "# \tprint(testX.shape, testy.shape)\n",
    "# \t# zero-offset class values\n",
    "# \ttrainy = trainy - 1\n",
    "# \ttesty = testy - 1\n",
    "# \t# one hot encode y\n",
    "# \ttrainy = to_categorical(trainy)\n",
    "# \ttesty = to_categorical(testy)\n",
    "# \tprint(trainX.shape, trainy.shape, testX.shape, testy.shape)\n",
    "# \treturn trainX, trainy, testX, testy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00034496,  0.00246692,  0.00246577, ..., -0.04874717,\n",
       "        -0.04722313, -0.0366187 ],\n",
       "       [-0.00680798, -0.00388054, -0.00985425, ..., -0.02406255,\n",
       "        -0.02137506, -0.0730015 ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # fit and evaluate a model\n",
    "# def evaluate_model(trainX, trainy, testX, testy):\n",
    "# \tverbose, epochs, batch_size = 0, 15, 70\n",
    "# # \tn_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
    "# \tmodel = Sequential()\n",
    "# \tmodel.add(LSTM(100, input_shape=(n_timesteps,n_features))) #LSTM('no. of lstm blocks', input_shape(time_Steps,features))\n",
    "# \tmodel.add(Dropout(0.5))\n",
    "# \tmodel.add(Dense(100, activation='relu'))\n",
    "# \tmodel.add(Dense(n_outputs, activation='softmax'))\n",
    "# \tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# \t# fit network\n",
    "# \tmodel.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "# \t# evaluate model\n",
    "# \t_, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n",
    "# \treturn accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # summarize scores\n",
    "# def summarize_results(scores):\n",
    "# \tprint(scores)\n",
    "# \tm, s = mean(scores), std(scores)\n",
    "# \tprint('Accuracy: %.3f%% (+/-%.3f)' % (m, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run an experiment\n",
    "def run_experiment(repeats=10):\n",
    "\t# load data\n",
    "\ttrain_data, train_labels, test_data, test_labels = load_dataset()\n",
    "\t# repeat experiment\n",
    "# \tscores = list()\n",
    "\tfor r in range(repeats):\n",
    "\t\tscore = evaluate_model(train_data, train_labels, test_data, test_labels)\n",
    "\t\tscore = score * 100.0\n",
    "\t\tprint('>#%d: %.3f' % (r+1, score))\n",
    "\t\tscores.append(score)\n",
    "\t# summarize results\n",
    "\tsummarize_results(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_experiment()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3b33382a05bd3705430a25e9e272c47f692b4e9d763a072f74d3892fa8edad58"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
